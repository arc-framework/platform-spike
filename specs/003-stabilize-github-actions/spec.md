# Feature Specification: GitHub Actions CI/CD Optimization & Enterprise Standardization

**Feature Branch**: `003-stabilize-github-actions`  
**Created**: January 11, 2026  
**Status**: Draft  
**Input**: User request: "Analyze and stabilize GitHub Actions, create CI/CD suite with grouped actions, improve efficiency, remove unnecessary workflows, maintain enterprise standards, and ensure only necessary actions run at merge time with output summaries"

---

## Overview

The A.R.C. Platform currently has **12 GitHub Actions workflows** with significant redundancy, unclear execution contexts, and inefficient resource usage. This feature consolidates, optimizes, and standardizes the CI/CD pipeline according to enterprise best practices while reducing maintenance burden by 70% and improving execution speed by 60%.

###

 Problem Statement

**Current Issues:**
1. **Workflow Redundancy:** 5 publish workflows (publish-communication, publish-data-services, publish-gateway, publish-observability, publish-tools) perform identical operations with different image lists
2. **Over-Validation:** Validation workflows run on both PR and main branch, wasting CI/CD minutes on already-validated code
3. **Manual Operations:** No automated deployment pipeline; all publishing is manual via `workflow_dispatch`
4. **Missing Observability:** No job summaries, PR comments, or visual feedback on workflow outcomes
5. **Inefficient Caching:** Minimal cache strategy leading to 5-8 minute builds that could be <60 seconds
6. **Security Gaps:** No SBOM generation, image signing, or CVE tracking
7. **No Orchestration:** Multiple independent workflows with unclear dependencies and execution order

**Impact:**
- Developers wait 8+ minutes for PR validation (should be <3 minutes)
- Platform operators manually trigger 5 separate publish workflows (should be 1 automated)
- Security team can't audit dependencies (no SBOM)
- No visibility into build failures without clicking into logs
- ~900 CI/CD minutes/month with 40% waste from redundant operations

### Goal

Transform GitHub Actions from **functional but inefficient** to **enterprise-grade CI/CD pipeline** with:
- **58% reduction** in workflow file count (12 ‚Üí 5 core workflows via intelligent orchestration)
- **60% faster** PR validation (8 min ‚Üí 3 min) through aggressive caching
- **28% reduction** in CI/CD minutes (908 ‚Üí 650 min/month) via optimizations
- **100% automation** of publish/deploy operations (zero manual workflows)
- **Full observability** via job summaries, PR comments, and metrics tracking
- **Enterprise security** with SBOM, signing, and CVE tracking
- **Zero rate limiting** issues via controlled parallel execution

---

## User Scenarios & Testing *(mandatory)*

### User Story 1 - Developer Gets Fast PR Feedback (Priority: P1) üéØ MVP

A developer creates a pull request with changes to `arc-sherlock-brain` service code. They need fast feedback on whether their changes pass linting, security checks, and build validation before requesting review from the team.

**Why this priority**: Developer productivity is directly tied to feedback loop speed. 8-minute PR checks block context-switching and reduce flow state. Sub-3-minute validation enables 10+ PRs per day vs 4-5 PRs with slow checks.

**Independent Test**: Create PR modifying `services/arc-sherlock-brain/src/main.py` (code only, not dependencies). Measure time from push to "All checks passed" status. Should complete in under 3 minutes with 85%+ cache hit rate.

**Acceptance Scenarios**:

1. **Given** developer pushes code-only changes to PR, **When** CI/CD runs, **Then** validation completes in <3 minutes using cached dependencies
2. **Given** PR validation is running, **When** developer pushes new commit, **Then** old workflow is automatically canceled and new one starts immediately
3. **Given** validation completes, **When** developer views PR page, **Then** they see job summary with visual pass/fail indicators without clicking into workflow logs
4. **Given** Dockerfile changes are included, **When** hadolint runs, **Then** actionable error messages with fix suggestions appear in PR comments
5. **Given** security scan detects CRITICAL CVE, **When** workflow fails, **Then** PR comment includes CVE ID, affected package, and remediation steps

**Success Metrics:**
- Average PR validation time: <3 minutes (target), currently 8 minutes
- Cache hit rate: >85% (target), currently ~40%
- Developer satisfaction: "Can iterate without waiting"

---

### User Story 2 - Platform Operator Publishes Images Automatically (Priority: P1) üéØ MVP

A platform operator merges a PR to main branch that updates the `arc-sherlock-brain` service. The system should automatically build, test, and publish the updated image to GHCR dev registry without manual intervention.

**Why this priority**: Manual publishing is error-prone (forgetting to publish, wrong tags, inconsistent timing). Automated deployment is foundation for CI/CD maturity. Current state requires triggering 5 separate manual workflows.

**Independent Test**: Merge PR updating `services/arc-sherlock-brain/Dockerfile` to main branch. Verify image is automatically built, scanned, signed, and pushed to `ghcr.io/arc/arc-sherlock-brain:dev-<sha>` within 5 minutes of merge. Verify SBOM and provenance attestations are generated.

**Acceptance Scenarios**:

1. **Given** PR is merged to main, **When** merge completes, **Then** affected service images are automatically built and pushed to dev registry with appropriate tags
2. **Given** service build succeeds, **When** security scan runs, **Then** CRITICAL CVEs block publish and create GitHub Issue with details
3. **Given** security scan passes, **When** image is published, **Then** SBOM is generated and attached as artifact
4. **Given** image is published to dev, **When** deployment completes, **Then** Slack notification is sent with build details and deploy URL
5. **Given** multiple services changed in one PR, **When** merge occurs, **Then** all affected services are built in parallel and published atomically

**Success Metrics:**
- Zero manual workflow triggers (currently 5 manual workflows)
- Dev deployment time: <5 minutes from merge
- SBOM coverage: 100% of published images

---

### User Story 3 - Security Team Audits Dependencies (Priority: P1) üéØ MVP

A security engineer needs to audit all A.R.C. service dependencies to identify outdated packages, license compliance issues, and vulnerable transitive dependencies for quarterly compliance report.

**Why this priority**: Compliance requirements (FDA, automotive, financial) mandate SBOM and CVE tracking. Current state has no dependency visibility. Manual audits take 8+ hours per quarter.

**Independent Test**: Run SBOM generation for all services. Export consolidated dependency list with licenses, versions, and known CVEs. Verify report shows all Python packages, Alpine packages, and transitive dependencies. Should complete in <10 minutes.

**Acceptance Scenarios**:

1. **Given** security engineer triggers audit workflow, **When** it completes, **Then** consolidated SBOM report is generated showing all dependencies across all services
2. **Given** SBOM is generated, **When** engineer reviews it, **Then** each dependency shows: name, version, license, CVE count, last updated date
3. **Given** new CVE is published for dependency, **When** daily security scan runs, **Then** GitHub Issue is automatically created with CVE details and affected services
4. **Given** HIGH CVE is detected, **When** issue is created, **Then** SLA timer starts (24 hours to fix) and Slack alert is sent
5. **Given** dependency violates license policy (GPL in proprietary code), **When** scan detects it, **Then** build fails with clear policy violation message

**Success Metrics:**
- SBOM generation time: <10 minutes (full platform)
- CVE detection lag: <24 hours from publication
- License compliance: 100% visibility, zero violations

---

### User Story 4 - DevOps Engineer Understands Build Pipeline (Priority: P2)

A DevOps engineer investigates why a deployment failed. They need to understand workflow execution flow, see which jobs ran in which order, identify the failure point, and access relevant logs/artifacts quickly.

**Why this priority**: Troubleshooting is 60% of DevOps time. Poor observability means 30+ minutes searching logs. Good job summaries and PR comments enable <5 minute diagnosis.

**Independent Test**: Simulate failed build (inject security CVE). Verify engineer can identify failure cause from PR page alone without clicking into workflow logs. Job summary should show: which service failed, why, what the fix is, and link to documentation.

**Acceptance Scenarios**:

1. **Given** workflow completes (success or failure), **When** engineer views PR page, **Then** job summary shows visual status of each job with pass/fail indicators and execution time
2. **Given** build fails, **When** job summary is generated, **Then** it includes: failure reason, affected file/line, suggested fix, and link to documentation
3. **Given** security scan fails, **When** engineer reviews summary, **Then** they see: CVE ID, severity, affected package, version to upgrade to, and CVSS score
4. **Given** multiple workflows run in parallel, **When** all complete, **Then** single aggregated "PR Checks" status shows overall pass/fail
5. **Given** engineer wants historical data, **When** they access workflow dashboard, **Then** trends for build time, image size, CVE count are visible over last 30 days

**Success Metrics:**
- Time to diagnose failure: <5 minutes (currently 30 minutes)
- Log click-through rate: <20% (most info in summary)
- Mean time to recovery (MTTR): <30 minutes

---

### User Story 5 - Architect Orchestrates Complex Workflows (Priority: P2)

A platform architect needs to implement blue/green deployment with smoke tests, rollback capability, and manual approval gate for production releases while maintaining automated dev/staging deployments.

**Why this priority**: Production deployment safety requires orchestration, gates, and rollback. Current manual process is risky. Enterprise CI/CD requires this capability.

**Independent Test**: Create git tag `v1.0.0`. Verify automated workflow: builds images, tags with semver, deploys to staging, runs smoke tests, waits for manual approval, deploys to production, creates GitHub Release. Any failure should rollback automatically.

**Acceptance Scenarios**:

1. **Given** tag is pushed (v1.0.0), **When** release workflow starts, **Then** images are built with immutable semver tags (not latest)
2. **Given** images are built, **When** staging deployment starts, **Then** blue/green strategy is used (deploy to green, switch traffic, keep blue for rollback)
3. **Given** staging deployment completes, **When** smoke tests run, **Then** health checks, API tests, and load tests execute automatically
4. **Given** smoke tests pass, **When** workflow reaches production gate, **Then** Slack notification requests manual approval with staging test results
5. **Given** production deployment fails, **When** failure is detected, **Then** automatic rollback to previous version occurs and incident is created

**Success Metrics:**
- Deployment automation: 100% (dev/staging), 95% (prod with manual gate)
- Rollback time: <5 minutes (automated)
- Deployment failure rate: <2% (improved from ~10% manual)

---

### User Story 6 - Cost Controller Optimizes CI/CD Spend (Priority: P3)

A finance/DevOps lead needs to understand CI/CD costs, identify expensive workflows, and optimize runner usage to stay within budget as team grows from 3 to 10 developers.

**Why this priority**: Proactive cost management prevents surprises. Free tier is 2,000 min/month; 10 active developers could exceed this. Need visibility before problem occurs.

**Independent Test**: Generate cost report showing: minutes used per workflow, cost per service build, trend over last 30 days, projected monthly cost. Identify top 3 expensive workflows and recommend optimizations.

**Acceptance Scenarios**:

1. **Given** cost tracking is enabled, **When** workflow completes, **Then** execution time is logged to metrics dashboard with workflow name, trigger type, and cost
2. **Given** monthly usage approaches 80% of free tier, **When** threshold is reached, **Then** Slack alert warns team with usage breakdown and optimization suggestions
3. **Given** workflow is identified as expensive, **When** engineer reviews it, **Then** dashboard shows: execution frequency, average duration, cache hit rate, potential savings
4. **Given** optimization is implemented (caching), **When** workflow runs again, **Then** cost delta is tracked showing savings (e.g., "45% faster, saved $0.12")
5. **Given** team wants to project costs, **When** they view dashboard, **Then** forecast shows: current trajectory, expected monthly cost, break-even point for self-hosted runners

**Success Metrics:**
- Cost visibility: 100% (track every workflow)
- Monthly cost: Stay within free tier (2,000 min)
- Cost per build reduction: 28% (via caching/optimization)

---

## Functional Requirements

### FR1: Workflow Consolidation (P1)

**Requirement:** Consolidate 12 workflows into 4 core orchestration workflows + 1 unified publish orchestrator + 5 reusable workflows + 5 composite actions.

**Core Workflows:**
1. `pr-checks.yml` - Orchestrates all PR validation (calls reusable workflows)
2. `main-deploy.yml` - Automated dev deployment on merge to main
3. `release.yml` - Production deployment on tag push with manual gate
4. `scheduled-maintenance.yml` - Nightly security scans, weekly base image builds

**Publish Orchestration** (addresses GHCR rate limiting & distribution):
5. `publish-vendor-images.yml` - **Single orchestrator** that calls publish jobs in controlled sequence

**Reusable Workflows** (in `.github/workflows/` prefixed with `_reusable-`):
1. `_reusable-validate.yml` - Linting, structure checks, dockerfile validation
2. `_reusable-build.yml` - Docker image builds with caching and multi-arch
3. `_reusable-security.yml` - Trivy scans, SBOM generation, CVE tracking
4. `_reusable-test.yml` - Integration tests, health checks, smoke tests
5. `_reusable-publish-group.yml` - Push image group to GHCR with rate limit handling

**Composite Actions** (in `.github/actions/`):
1. `setup-arc-python/` - Python 3.11 + pip cache + tools (ruff, black, mypy)
2. `setup-arc-docker/` - GHCR login + BuildKit + cache configuration
3. `setup-arc-validation/` - Install hadolint, trivy, shellcheck
4. `arc-job-summary/` - Generate markdown summary with pass/fail visualization
5. `arc-notify/` - Send Slack notifications (future), create GitHub Issues

**Publish Strategy** (solves GHCR rate limiting problem):

Instead of consolidating 5 publish workflows into 1 monolithic job, we use **controlled parallel execution with job dependencies**:

```yaml
# publish-vendor-images.yml
name: Publish Vendor Images

on:
  workflow_dispatch:
    inputs:
      groups:
        description: 'Which groups to publish (all, gateway, data, observability, communication, tools)'
        required: false
        default: 'all'
        type: choice
        options: ['all', 'gateway', 'data', 'observability', 'communication', 'tools']
      
  schedule:
    - cron: '0 8 * * 0'  # Weekly Sunday 8 AM UTC

jobs:
  # Gateway & Identity (4 images, ~12 min)
  publish-gateway:
    if: ${{ inputs.groups == 'all' || inputs.groups == 'gateway' || github.event_name == 'schedule' }}
    uses: ./.github/workflows/_reusable-publish-group.yml
    with:
      group_name: 'Gateway & Identity'
      config_file: '.github/config/publish-gateway.json'
    secrets: inherit

  # Data Services (5 images, ~15 min) - runs AFTER gateway to avoid rate limits
  publish-data:
    needs: [publish-gateway]
    if: ${{ inputs.groups == 'all' || inputs.groups == 'data' || github.event_name == 'schedule' }}
    uses: ./.github/workflows/_reusable-publish-group.yml
    with:
      group_name: 'Data Services'
      config_file: '.github/config/publish-data.json'
    secrets: inherit

  # Observability (6 images, ~18 min) - runs AFTER data services
  publish-observability:
    needs: [publish-data]
    if: ${{ inputs.groups == 'all' || inputs.groups == 'observability' || github.event_name == 'schedule' }}
    uses: ./.github/workflows/_reusable-publish-group.yml
    with:
      group_name: 'Observability'
      config_file: '.github/config/publish-observability.json'
    secrets: inherit

  # Communication (3 images, ~9 min) - can run in PARALLEL with observability
  publish-communication:
    needs: [publish-gateway]  # Only depends on gateway, not data/observability
    if: ${{ inputs.groups == 'all' || inputs.groups == 'communication' || github.event_name == 'schedule' }}
    uses: ./.github/workflows/_reusable-publish-group.yml
    with:
      group_name: 'Communication'
      config_file: '.github/config/publish-communication.json'
    secrets: inherit

  # Tools (5 images, ~15 min) - can run in PARALLEL with observability
  publish-tools:
    needs: [publish-gateway]  # Only depends on gateway, not data/observability
    if: ${{ inputs.groups == 'all' || inputs.groups == 'tools' || github.event_name == 'schedule' }}
    uses: ./.github/workflows/_reusable-publish-group.yml
    with:
      group_name: 'Tools'
      config_file: '.github/config/publish-tools.json'
    secrets: inherit

  # Summary job - aggregates all results
  publish-summary:
    needs: [publish-gateway, publish-data, publish-observability, publish-communication, publish-tools]
    if: always()
    runs-on: ubuntu-latest
    steps:
      - name: Generate Summary
        run: |
          echo "## üì¶ Vendor Image Publishing Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Group | Status | Duration |" >> $GITHUB_STEP_SUMMARY
          echo "|-------|--------|----------|" >> $GITHUB_STEP_SUMMARY
          echo "| Gateway | ${{ needs.publish-gateway.result }} | - |" >> $GITHUB_STEP_SUMMARY
          echo "| Data Services | ${{ needs.publish-data.result }} | - |" >> $GITHUB_STEP_SUMMARY
          echo "| Observability | ${{ needs.publish-observability.result }} | - |" >> $GITHUB_STEP_SUMMARY
          echo "| Communication | ${{ needs.publish-communication.result }} | - |" >> $GITHUB_STEP_SUMMARY
          echo "| Tools | ${{ needs.publish-tools.result }} | - |" >> $GITHUB_STEP_SUMMARY
```

**Image Configuration** (move hardcoded lists to JSON files):

```json
// .github/config/publish-gateway.json
{
  "images": [
    {
      "source": "traefik:v3.0",
      "target": "arc-heimdall-gateway",
      "platforms": ["linux/amd64", "linux/arm64"]
    },
    {
      "source": "unleashorg/unleash-server:latest",
      "target": "arc-mystique-flags",
      "platforms": ["linux/amd64", "linux/arm64"]
    },
    {
      "source": "oryd/kratos:latest",
      "target": "arc-jarvis-identity",
      "platforms": ["linux/amd64", "linux/arm64"]
    },
    {
      "source": "infisical/infisical:latest",
      "target": "arc-fury-vault",
      "platforms": ["linux/amd64"]
    }
  ],
  "rate_limit_delay": 30,
  "retry_attempts": 3
}
```

**Benefits of This Architecture:**

1. **Rate Limit Control:** Sequential execution with `needs:` dependencies prevents overwhelming GHCR
2. **Selective Publishing:** Can publish individual groups via `workflow_dispatch` inputs
3. **Parallel Optimization:** Communication and Tools run in parallel with Observability (3 streams instead of 1)
4. **Fault Isolation:** If Gateway fails, Communication/Tools can still succeed (no total failure)
5. **Maintainability:** Image lists in JSON are easier to update than YAML multiline strings
6. **Observability:** Single aggregated summary showing all results
7. **Flexibility:** Can trigger "publish only gateway" without running all 25 images

**Execution Flow:**
```
START
  ‚Üì
Gateway (4 images, 12 min)
  ‚Üì
  ‚îú‚îÄ‚Üí Data Services (5 images, 15 min) ‚Üí Observability (6 images, 18 min)
  ‚îú‚îÄ‚Üí Communication (3 images, 9 min)
  ‚îî‚îÄ‚Üí Tools (5 images, 15 min)
  ‚Üì
Summary (aggregate results)
END

Total Time: ~30-35 minutes (with parallel execution)
vs. 60+ minutes if fully sequential
vs. timeout risk if fully parallel
```

**Justification:**
- Reduces file count from 12 ‚Üí 5 core workflows (still a reduction)
- Eliminates 200+ lines of duplicate code (reusable-publish-group.yml)
- **Solves GHCR rate limiting** via controlled parallelism
- **Solves distribution problem** via job dependencies and selective triggers
- Maintains single source of truth (JSON config files)
- Easier to maintain (update JSON, not YAML)

---

### FR2: Intelligent Trigger Management (P1)

**Requirement:** Only run validation on PRs, only run deployment on merge, never re-validate already-validated code.

**PR Triggers** (`pr-checks.yml`):
```yaml
on:
  pull_request:
    types: [opened, synchronize, reopened]
    paths:
      - 'services/**'
      - 'core/**'
      - 'plugins/**'
      - '.docker/**'
      - '**/Dockerfile'
      - '**/requirements.txt'
      - '.github/workflows/**'
```

**Main Triggers** (`main-deploy.yml`):
```yaml
on:
  push:
    branches: [main]
    paths:
      - 'services/**'
      - 'core/**'
      - 'plugins/**'
      - '.docker/**'
```

**Scheduled Triggers** (`scheduled-maintenance.yml`):
```yaml
on:
  schedule:
    - cron: '0 6 * * *'  # Daily 6 AM UTC - Security scans
    - cron: '0 6 * * 0'  # Weekly Sunday 6 AM - Base image rebuilds
```

**Concurrency Control:**
```yaml
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true  # Cancel old runs on new push
```

**Justification:**
- Eliminates duplicate validation on main (saves ~50 min/month)
- Auto-cancels superseded PR runs (saves ~80 min/month)
- Clear separation: validate on PR, deploy on merge, maintain on schedule

---

### FR3: Aggressive Caching Strategy (P1)

**Requirement:** Implement 3-tier caching to achieve <60 second incremental builds.

**Tier 1: Tool Cache** (composite action):
```yaml
- uses: actions/cache@v4
  with:
    path: |
      ~/bin/hadolint
      ~/bin/trivy
    key: tools-${{ runner.os }}-v1
    restore-keys: tools-${{ runner.os }}-
```

**Tier 2: Dependency Cache** (setup actions):
```yaml
- uses: actions/setup-python@v5
  with:
    python-version: '3.11'
    cache: 'pip'  # Auto-caches based on requirements.txt hash
```

**Tier 3: Docker Build Cache** (BuildKit):
```yaml
- uses: docker/build-push-action@v5
  with:
    context: ${{ matrix.service.path }}
    cache-from: type=gha
    cache-to: type=gha,mode=max
```

**Performance Targets:**
- Code-only changes: <60 seconds (currently ~5 minutes)
- Dependency changes: <3 minutes (currently ~5 minutes)
- Clean builds: <6 minutes (acceptable for infrequent occurrence)
- Cache hit rate: >85% (currently ~40%)

**Justification:**
- 85% faster incremental builds (5 min ‚Üí 45 sec)
- 28% reduction in monthly CI/CD minutes
- Developer productivity improvement (10+ PRs/day possible)

---

### FR4: Comprehensive Job Summaries (P1)

**Requirement:** Every workflow must generate visual job summary visible on PR page without clicking into logs.

**Summary Structure:**
```markdown
## üöÄ A.R.C. CI/CD Results

### Build Status
| Service | Status | Duration | Size | Change |
|---------|--------|----------|------|--------|
| arc-sherlock-brain | ‚úÖ Pass | 42s | 445MB | +2MB (+0.4%) |
| arc-scarlett-voice | ‚úÖ Pass | 38s | 412MB | -5MB (-1.2%) |

### Security Scan
| Severity | Count | Change |
|----------|-------|--------|
| CRITICAL | 0 | ‚úÖ None |
| HIGH | 2 | ‚ö†Ô∏è +1 (see details) |

### Validation Results
- ‚úÖ Dockerfile linting: All 7 files passed
- ‚úÖ Structure validation: SERVICE.MD synchronized
- ‚úÖ Integration tests: 45/45 passed (3m 12s)

### üìä Performance
- Cache hit rate: 92% (üéØ target: 85%)
- Total duration: 3m 45s (üéØ target: <5m)

[View detailed logs](#) | [View trends](#)
```

**Implementation:**
```yaml
- name: Generate Summary
  if: always()
  run: |
    cat results.json | jq -r '
      "## üöÄ A.R.C. CI/CD Results",
      "",
      "### Build Status",
      "| Service | Status | Duration | Size |",
      "|---------|--------|----------|------|",
      (.builds[] | "| \(.service) | \(.status) | \(.duration) | \(.size) |")
    ' >> $GITHUB_STEP_SUMMARY
```

**Justification:**
- Reduces time to understand build result from 2 minutes (click, scroll logs) to 5 seconds (scan summary)
- Provides actionable data (what changed, why failed, how to fix)
- Improves developer experience significantly

---

### FR5: SBOM & Image Signing (P2)

**Requirement:** Generate SBOM for all images, sign production images with Cosign, store provenance attestations.

**SBOM Generation:**
```yaml
- uses: docker/build-push-action@v5
  with:
    sbom: true  # Generates SPDX SBOM
    outputs: type=image,push=true
```

**Image Signing:**
```yaml
- name: Sign image with Cosign
  run: |
    cosign sign --yes \
      --key env://COSIGN_KEY \
      ghcr.io/arc/${{ matrix.service }}:${{ github.sha }}
  env:
    COSIGN_KEY: ${{ secrets.COSIGN_PRIVATE_KEY }}
    COSIGN_PASSWORD: ${{ secrets.COSIGN_PASSWORD }}
```

**Provenance:**
```yaml
- uses: slsa-framework/slsa-github-generator/.github/workflows/generator_container_slsa3.yml@v1.9.0
  with:
    image: ghcr.io/arc/${{ matrix.service }}
    digest: ${{ steps.build.outputs.digest }}
```

**Justification:**
- Compliance requirement for regulated industries
- Supply chain security (detect compromised dependencies)
- License compliance (identify GPL in proprietary code)

---

### FR6: Automated Service Discovery (P2)

**Requirement:** Dynamically discover which services to build based on SERVICE.MD, not hardcoded lists.

**Discovery Job:**
```yaml
jobs:
  discover-services:
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.parse.outputs.matrix }}
    steps:
      - uses: actions/checkout@v4
      
      - name: Parse SERVICE.MD
        id: parse
        run: |
          # Extract services from SERVICE.MD table
          # Output JSON matrix
          python scripts/ci/parse-services.py > services.json
          echo "matrix=$(cat services.json)" >> $GITHUB_OUTPUT

  build-services:
    needs: discover-services
    strategy:
      matrix: ${{ fromJSON(needs.discover-services.outputs.matrix) }}
    steps:
      - name: Build ${{ matrix.service }}
        run: docker build -t ${{ matrix.service }} ${{ matrix.path }}
```

**Justification:**
- Single source of truth (SERVICE.MD)
- No hardcoded service lists to maintain
- Automatically includes new services when added to SERVICE.MD

---

## Non-Functional Requirements

### NFR1: Performance

- **PR validation:** <3 minutes (85th percentile)
- **Service build (cached):** <60 seconds for code-only changes
- **Service build (cold):** <6 minutes for full rebuild
- **Security scan:** <5 minutes for full platform
- **Cache hit rate:** >85% for typical development patterns

**Measurement:** Track in metrics dashboard, alert if degradation >20%

---

### NFR2: Reliability

- **Workflow success rate:** >95% (excluding legitimate failures like CVEs)
- **Flaky test rate:** <2% (tests should be deterministic)
- **Mean time to recovery:** <30 minutes from detection to fix deployed

**Measurement:** Track success rate per workflow, identify flaky patterns

---

### NFR3: Cost

- **Monthly CI/CD minutes:** <1,500 minutes (75% of free tier)
- **Cost per service build:** <2 minutes (with caching)
- **Break-even for self-hosted:** Not until >5,000 min/month

**Measurement:** Track via cost dashboard, project monthly usage

---

### NFR4: Security

- **CVE detection lag:** <24 hours from publication to detected
- **CRITICAL CVE fix SLA:** <24 hours from detection to deployed
- **HIGH CVE fix SLA:** <7 days from detection to deployed
- **SBOM coverage:** 100% of published images
- **Image signing:** 100% of production images

**Measurement:** Track in security dashboard, alert on SLA violations

---

### NFR5: Maintainability

- **Workflow complexity:** Max 200 lines per workflow file
- **Code reuse:** >80% of setup logic in composite actions/reusable workflows
- **Documentation:** Every workflow has header comment explaining purpose/triggers
- **Action pinning:** 100% of actions pinned to SHA256

**Measurement:** Code review checklist, automated linting

---

## Edge Cases

### EC1: GHCR Rate Limiting & Concurrent Pushes

**Scenario:** Publishing 25 vendor images simultaneously to GHCR causes rate limiting errors (HTTP 429) or timeout failures.

**Problem Details:**
- GHCR has rate limits: ~100 requests/hour for unauthenticated, ~5000/hour for authenticated
- Multi-arch builds (amd64 + arm64) = 2x manifest pushes per image
- 25 images √ó 2 architectures = 50 manifest pushes
- Concurrent pushes increase memory/CPU on runners
- GitHub Actions runners have limited resources (7GB RAM, 2 CPU cores)

**Handling Strategy:**

1. **Controlled Parallelism via Job Dependencies:**
   ```yaml
   jobs:
     gateway:    # Runs first (4 images)
       ...
     data:
       needs: [gateway]  # Sequential after gateway
       ...
     observability:
       needs: [data]     # Sequential after data
       ...
     communication:
       needs: [gateway]  # Parallel with data/observability
       ...
   ```

2. **Rate Limit Delay Between Images:**
   ```yaml
   # In _reusable-publish-group.yml
   - name: Push image with rate limit handling
     run: |
       for image in $IMAGES; do
         docker push $image
         sleep 30  # 30 second delay between pushes
       done
   ```

3. **Retry Logic with Exponential Backoff:**
   ```yaml
   - name: Push with retry
     uses: nick-invision/retry@v2
     with:
       timeout_minutes: 10
       max_attempts: 3
       retry_wait_seconds: 60
       command: docker push ${{ matrix.image }}
   ```

4. **Selective Publishing:**
   - Publish only changed image groups
   - Manual trigger can target specific groups
   - Scheduled runs publish all (off-peak hours)

5. **Monitor Rate Limit Headers:**
   ```bash
   RATE_LIMIT=$(curl -H "Authorization: token $GITHUB_TOKEN" \
     https://api.github.com/rate_limit | jq .rate.remaining)
   if [ $RATE_LIMIT -lt 100 ]; then
     echo "Rate limit low, waiting 60s"
     sleep 60
   fi
   ```

**Success Metrics:**
- Zero rate limit errors in last 30 days
- <5% retry rate on image pushes
- Total publish time: 30-35 minutes (acceptable)

---

### EC2: Circular Dependencies

**Scenario:** Service A depends on base image X, which depends on SERVICE.MD, which includes Service A.

**Handling:**
- Dependency graph analyzer detects cycles before build starts
- Fail fast with clear error message
- Document build order in SERVICE.MD

---

### EC3: Monorepo Changes (Everything Changed)

**Scenario:** Developer refactors shared library affecting all 7 services.

**Handling:**
- Detect via git diff (all services have changes)
- Build services in parallel (not sequentially)
- Fail fast on first failure (don't build all 7 if first fails)
- Show aggregated summary (7/7 built, 2 failed)

---

### EC4: Flaky Security Scans

**Scenario:** Trivy database update mid-scan causes inconsistent results.

**Handling:**
- Pin Trivy database version for reproducibility
- Allow manual re-run of security scan
- Timeout after 10 minutes (don't hang forever)
- Cache Trivy database (don't download every time)

---

### EC5: GitHub Actions Outage

**Scenario:** GitHub Actions is down, PR can't be validated.

**Handling:**
- Show clear status message ("CI/CD provider unavailable")
- Allow manual override via label ("skip-ci" label)
- Document fallback process (local validation)
- SLA: GitHub Actions has 99.9% uptime

---

### EC6: Cache Corruption

**Scenario:** Cache contains corrupted dependencies causing build failures.

**Handling:**
- Cache key includes checksum of lockfile (auto-invalidates)
- Manual cache clear via workflow_dispatch input
- Fallback to clean build if cache load fails
- Monitor cache hit rate (detect if caching is ineffective)

---

### EC7: Secrets Rotation

**Scenario:** COSIGN_PRIVATE_KEY is rotated, old images can't be verified.

**Handling:**
- Maintain 2 keys during rotation (old + new)
- Sign with both keys during transition period
- Document rotation procedure
- Alert when key expiry approaches (90 days)

---

## Success Criteria

**Quantitative Metrics:**
- ‚úÖ 58% reduction in workflow files (12 ‚Üí 5 core workflows) - accounts for orchestration overhead
- ‚úÖ 60% faster PR validation (8 min ‚Üí 3 min average)
- ‚úÖ 28% reduction in CI/CD minutes (908 ‚Üí 650 min/month)
- ‚úÖ 85%+ cache hit rate (currently ~40%)
- ‚úÖ 100% SBOM coverage for published images
- ‚úÖ Zero manual publish operations (currently 100% manual)
- ‚úÖ Zero GHCR rate limit errors (via controlled parallelism)

**Qualitative Metrics:**
- ‚úÖ Developer feedback: "CI/CD is fast and informative"
- ‚úÖ Operator feedback: "Deployments are automated and reliable"
- ‚úÖ Security feedback: "We have full visibility into dependencies"

**MVP Definition** (User Stories 1-3):
- PR validation runs in <3 minutes
- Merge to main automatically deploys to dev
- SBOM is generated for all images

**Full Feature** (User Stories 1-5):
- Production deployment with manual gate
- Blue/green deployments with rollback
- Full observability dashboard

---

## Out of Scope

**Not Included in This Feature:**
- ‚ùå Kubernetes deployment (future feature)
- ‚ùå External metrics dashboard (Datadog/Grafana) - use GitHub Actions metrics
- ‚ùå Self-hosted runners (not cost-effective yet)
- ‚ùå Multi-cloud deployment (Azure/GCP) - GitHub/GHCR only
- ‚ùå Advanced testing (load tests, chaos engineering) - smoke tests only
- ‚ùå Dependency update automation (Dependabot/Renovate) - separate feature

**Explicitly Deferred:**
- Infrastructure as Code (Terraform/Pulumi) CI/CD
- Database migration CI/CD
- Compliance reporting (SOC2/HIPAA automation)

---

## Dependencies

**External Dependencies:**
- GitHub Actions (SaaS, 99.9% uptime SLA)
- GHCR (GitHub Container Registry)
- Trivy security database (maintained by Aqua Security)
- Cosign signing infrastructure (Sigstore project)

**Internal Dependencies:**
- SERVICE.MD must be accurate (source of truth)
- Validation scripts must exist (`scripts/validate/*`)
- Base images must be published before services can build

**Breaking Changes:**
- None - all changes are additive or refinements to existing workflows

---

## Rollout Plan

**Phase 1: Setup & Consolidation** (Week 1)
- Create composite actions (setup-arc-*)
- Create reusable workflows (_reusable-*)
- Migrate one publish workflow as proof of concept

**Phase 2: PR Validation** (Week 2)
- Implement pr-checks.yml orchestration
- Add caching to all validation jobs
- Add job summaries with visual feedback

**Phase 3: Automated Deployment** (Week 3)
- Implement main-deploy.yml for dev environment
- Add SBOM generation
- Add Slack notifications

**Phase 4: Production Pipeline** (Week 4)
- Implement release.yml with manual gate
- Add image signing with Cosign
- Add rollback capability

**Phase 5: Cleanup & Documentation** (Week 5)
- Deprecate old workflows
- Update documentation
- Train team on new workflows

---

## Appendix

### A. Workflow File Structure

```
.github/
‚îú‚îÄ‚îÄ actions/                         # Composite actions
‚îÇ   ‚îú‚îÄ‚îÄ setup-arc-python/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ action.yml
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îÇ   ‚îú‚îÄ‚îÄ setup-arc-docker/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ action.yml
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îÇ   ‚îú‚îÄ‚îÄ setup-arc-validation/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ action.yml
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îÇ   ‚îú‚îÄ‚îÄ arc-job-summary/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ action.yml
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îÇ   ‚îî‚îÄ‚îÄ arc-notify/
‚îÇ       ‚îú‚îÄ‚îÄ action.yml
‚îÇ       ‚îî‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ workflows/                       # Workflows
‚îÇ   ‚îú‚îÄ‚îÄ _reusable-validate.yml      # Reusable: Validation logic
‚îÇ   ‚îú‚îÄ‚îÄ _reusable-build.yml         # Reusable: Build logic
‚îÇ   ‚îú‚îÄ‚îÄ _reusable-security.yml      # Reusable: Security scan logic
‚îÇ   ‚îú‚îÄ‚îÄ _reusable-test.yml          # Reusable: Test logic
‚îÇ   ‚îú‚îÄ‚îÄ _reusable-publish.yml       # Reusable: Publish logic
‚îÇ   ‚îú‚îÄ‚îÄ pr-checks.yml               # Orchestration: PR validation
‚îÇ   ‚îú‚îÄ‚îÄ main-deploy.yml             # Orchestration: Dev deployment
‚îÇ   ‚îú‚îÄ‚îÄ release.yml                 # Orchestration: Production release
‚îÇ   ‚îú‚îÄ‚îÄ scheduled-maintenance.yml   # Orchestration: Nightly/weekly tasks
‚îÇ   ‚îî‚îÄ‚îÄ DEPRECATED/                 # Old workflows (kept for reference)
‚îÇ       ‚îú‚îÄ‚îÄ docker-publish.yml
‚îÇ       ‚îú‚îÄ‚îÄ publish-communication.yml
‚îÇ       ‚îî‚îÄ‚îÄ ... (5 more)
‚îî‚îÄ‚îÄ scripts/                         # Helper scripts
    ‚îî‚îÄ‚îÄ ci/
        ‚îú‚îÄ‚îÄ parse-services.py       # SERVICE.MD parser
        ‚îú‚îÄ‚îÄ generate-matrix.py      # Matrix generator
        ‚îî‚îÄ‚îÄ calculate-costs.sh      # Cost reporter
```

### B. Trigger Matrix

| Event | Workflow | Jobs | Duration | Purpose |
|-------|----------|------|----------|---------|
| PR opened/sync | pr-checks.yml | validate, build, security | 3 min | Fast feedback |
| Merge to main | main-deploy.yml | build, publish, deploy | 5 min | Dev deployment |
| Tag pushed | release.yml | build, publish, deploy, gate | 15 min | Production release |
| Daily 6AM UTC | scheduled-maintenance.yml | security-scan, dependency-check | 10 min | Proactive maintenance |
| Weekly Sun 6AM | scheduled-maintenance.yml | rebuild-base-images | 8 min | Security patches |

### C. Cost Projection

| Scenario | Minutes/Month | Cost | Notes |
|----------|---------------|------|-------|
| Current (12 workflows) | 908 | $0 (free tier) | 45% utilization |
| Optimized (4 workflows) | 650 | $0 (free tier) | 32% utilization |
| With 10 developers | 1,800 | $0 (free tier) | 90% utilization |
| Self-hosted break-even | 5,000 | $40/month | Not worth it yet |

### D. Migration Checklist

- [ ] Create composite actions (5 files)
- [ ] Create reusable workflows (5 files)
- [ ] Create orchestration workflows (4 files)
- [ ] Test pr-checks.yml on test PR
- [ ] Test main-deploy.yml on test branch
- [ ] Add caching to all jobs
- [ ] Add job summaries to all workflows
- [ ] Generate SBOM for one service (proof of concept)
- [ ] Sign one image with Cosign (proof of concept)
- [ ] Migrate remaining publish workflows
- [ ] Deprecate old workflows (move to DEPRECATED/)
- [ ] Update documentation
- [ ] Train team on new workflows

